---
title: "Basic Entropy Analysis of the MNIST dataset"
author: "F.J. Valverde-Albacete and C. Pelaez-Moreno"
date: "11/28/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This vignette tries to analyze the information content of the MNIST database.

## Installation

```{r general-libraries, echo=FALSE}
library(tidyverse)
library(entropies)
library(tensorflow)
#install_tensorflow()
```

```{r pressure, echo=FALSE}
library(keras)
#install_keras()#this should only be done once, seemingly!
GPU <- TRUE
GPU <- FALSE
#check this to enable GPU
use_session_with_seed(27, 
                      disable_gpu = !GPU,
                      disable_parallel_cpu = GPU
                      )
```

```{r load-data}
#library(ggplot2)#in tidyverse
library(reshape2)

mnist <- dataset_mnist()#Accesses aws!

# try plotting the pixel intensities for a random sample of 32 images, adapted from 
#https://tensorflow.rstudio.com/tfestimators/articles/examples/mnist.html
n <- 36
indices <- sample(nrow(mnist$train$x), size = n)
imageData <- mnist$train$x[indices, ,]
#original: #data <- array(mnist$train$x[indices, ,], dim = c(n, 28, 28))
melted <- melt(imageData, varnames = c("image", "x", "y"), value.name = "intensity")
ggplot(melted, aes(x = y, y = x, fill = intensity)) +
#ggplot(melted, aes(x = x, y = y, fill = intensity)) +
  geom_tile() +
  scale_fill_continuous(name = "Pixel Intensity") +
  scale_y_reverse() +
  facet_wrap(~ image, nrow = sqrt(n), ncol = sqrt(n)) +
  theme(
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    panel.spacing = unit(0, "lines"),
    axis.text = element_blank(),
    axis.ticks = element_blank()
  ) +
  labs(
    title = "MNIST Image Data",
    subtitle = "Visualization of a sample of images contained in MNIST data set.",
    x = NULL,
    y = NULL
  )
```

```{r data-exploration}
x_train <- mnist$train$x
y_train <- mnist$train$y
x_test <- mnist$test$x
y_test <- mnist$test$y
# reshape
x_train <- array_reshape(x_train, c(nrow(x_train), 28*28))
x_test <- array_reshape(x_test, c(nrow(x_test), 28*28))
# consult entropies
```

# The source analysis

## The distribution of labels

Below, the distribution of training and testing labels is plotted.

```{r}
round(table(y_train_labels)/length(y_train_labels), digits=2)
plot(as.factor(y_train_labels))
round(table(y_test_labels)/length(y_test_labels), digits=2)
plot(as.factor(y_test_labels))
```
The database is fairly balanced. And the split seems to be close to  stratified. The proportion for the split is 6/7 for train and 1/7 for testing.

This is ratified entropically
```{r}
rbind(
    sentropies(as.data.frame(y_train_labels))[1,],
    sentropies(as.data.frame(y_test_labels))[1,])
```

Incidentally, only a little bit over 3 bits is necessary for encoding the classes.

Maybe all of this information is better explored for the data as a source of information. 


## The entropic decomposition of the observations
This analysis is very costly in terms of entropy, due to the `r ncol(x_train)` input variables.

```{r source-entropy-analysis}
dsX <- infotheo::discretize(x_test, disc="equalwidth")
if (!exists("dataEntropies"))#only when we do not have this value
    dataEntropies <- sentropies(dsX)#Takes very long to work out

dataEntropies %>% filter(name=="ALL")#to see the overall entropy
printable <- dataEntropies
if (any((dataEntropies$H_Uxi == 0))){
    dataEntropies %>% filter(H_Uxi == 0)
    print(sprintf(
    "There are %d zero-entropy variables. Eliminating for smet...", 
    sum(as.numeric(dataEntropies$H_Uxi == 0))#Num of 0 entropy vars
    ))
    printable <- dataEntropies %>% filter(H_Uxi != 0)
}
#some variables are totally predictable
printable <- printable %>% filter(name != "ALL")
#draw the source triangle
smetX <- ggmetern( printable)  + 
        stat_density_tern(geom='polygon',
                        aes(fill=..level..),
                        #base=base,  ###NB Base Specification
                        colour='grey50') + 
        scale_fill_gradient(low='green',high='red')  +
        geom_point(size=1)
smetX
summary(printable$DeltaH_Pxi)
printable %>% filter(DeltaH_Pxi/H_Uxi > 0.9)
#printable %>% filter(!is.finite(H_Uxi) || !is.finite(M_Pxi))
```

So in essence:

* The features are really redundant
* Many of them do not really have any information
* The features are really far from uniformity

# Postscriptum

More information about the evaluation of sources with the Source Multivariate Entropy Triangle can be found in 

```{r echo=FALSE}
library(bibtex)
print(citation("entropies")['val:pel:17b'], style="text")
```

# Session information

```{r}
sessionInfo()
```
