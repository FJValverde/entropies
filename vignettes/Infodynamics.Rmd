---
title: "Infodynamics of classification"
author: "Francisco J. Valverde-Albacete & Carmen Pel√°ez Moreno"
date: "9 de mayo de 2016"
output: html_document
---
# Introduction

This vignette tries to demonstrate the use of Infodynamics for exploratory analysis of classification performance in Machine Learning. Infodynamics is an analogue of Thermodynamics for dealing with quantity of information instead of quantity of energy.

The premise is that if the information related to a random variable, the true class, wants to be "transported" somewhere to the predicted class, then the entropic balances of the true and predicted classes have to satisfy certain requisites.  


# Environment construction

## Knitting options

```{r setup, include=FALSE}
#knitr::opts_chunk$set(dev = 'pdf') # plots in pdf, better for publication
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment=NA, fig.width=6, fig.height=6)
#knitr::opts_chunk$set(comment=NA, fig.width=6, fig.height=4)
knitr::opts_chunk$set(warning=FALSE)# Should not appear in the knitted document
```

## Library loading

```{r libraries, include=FALSE}
library(tidyverse)  # Acceding to that infamous Mr. Wickham's requests!
# library(dplyr)     # That infamous Mr. Wickham!
# library(tidyr)     # Tidying tall & wide dataframes
library(infotheo)  # The functionality provided by this has to be rerouted through entropies
library(entropies) # This package
library(ggtern)    # Excellent package for ternary diagrams in the gg tradition
library(vcd)       # Categorical benchmarks
library(mlbench)   # ml benchmarkss
```
## Global parameter definitions


```{r}
fancy <- TRUE  # set this for nicer on-screen visualization
fancy <- FALSE # Set this for either printing matter or...
```

# Data preparation

## Datasets available

```{r explicit-datasets}
datasets <- getDatasets()
library(xtable)
ds4latexing <- datasets %>% dplyr::select(-className, -idNumber)
row.names(ds4latexing) <- NULL
names(ds4latexing) <- c("Dataset Name", "class card.", "num. features", "num. instances")
thisLatex <- xtable(ds4latexing, 
                    caption="Some datasets considered in this study",
                    label="tab:datasets")
align(thisLatex) <- xalign(thisLatex)
thisLatex
```

# Data exploration

## Obtaining the entropies

Obtain the entropies and some other data for plotting from all datasets.

<!-- # as per:  -->
<!-- # http://stackoverflow.com/questions/5234117/how-to-drop-columns-by-name-in-a-data-frame -->
<!-- # Don't EVER use subset in PROGRAMS! -->
<!-- #ds <- subset(ds, subset=1:nrow(ds), select=dsRecord$className, drop=TRUE) -->

```{r find-entropies}
cmet_edf <- tibble()# Gathers the CMET entropies
smet_edf <- tibble()
dsNames <- unique(datasets$name)#debug
#for(dsName in unique(datasets$name)){
    dsRecord <-  filter(datasets, name == dsName)
    ds <- evalDataset(dsName)
    nbins <- ceiling(dsRecord$m^(1/3))
#    for(withClass in withClasses){
#        if (withClass){
            print(sprintf("Analyzing dataset with class label: %s", dsName))
#        }else {
#            print(sprintf("Analyzing dataset without class label: %s", dsName))
            # as per: 
            # http://stackoverflow.com/questions/5234117/how-to-drop-columns-by-name-in-a-data-frame
            # Don't EVER use subset in PROGRAMS!
            #ds <- subset(ds, subset=1:nrow(ds), select=dsRecord$className, drop=TRUE)
#            ds <- ds[, !colnames(ds) == dsRecord$className] #fastest in bechnmark at bot. of url
#        }
        #Kdataset <- select(ds, which(names(ds) == dsRecord$className))
        Kdataset <- dplyr::select(ds, matches(dsRecord$className))
        smet_edf <- rbind(smet_edf, dsName, group="labels",
                          sentropies(Kdataset))
        Xdataset <- dplyr::select(ds, -matches(dsRecord$className))
        smet_edf <- rbind(smet_edf, dsName,group="observations",
                          sentropies(Xdataset,nbins)))
        cmet_edf <- rbind(cmet_edf,
                     cbind(dsName,
                           transform="observation",
                           jentropies(Kdataset,Xdataset)# observations
                           )
#                     sentropies(ds, nbins=ceiling(nrow(ds)^(1/3))) %>%
                    )
        #select those columns which are numeric
        numColumns <- sapply(Xdataset, is.numeric)
        if (!any(numColumns)) next#improve this for classifications
        #catColumns <- !numColumns#categorical columns in X (not including the class)
        Tdataset <- Xdataset[,numColumns]#Until  we know how to apply Box-Cox
        # Tdataset <- log(Xdataset)#Box-Cox transformation
        # cmet_edf <- rbind(cmet_edf,
        #              cbind(dsName,
        #                    transform="Box-Cox:log",
        #                    jentropies(Xdataset,Tdataset)
        #                    )
        #              )
        pca <- prcomp(Tdataset, center = TRUE, scale. = TRUE) 
        Ydataset <- cbind(
                        Xdataset[,!numColumns],
                        predict(pca, newdata=Tdataset)
        )
        cmet_edf <- rbind(cmet_edf,
                     cbind(dsName, 
                           transform="PCAonBoxCox:log",
                           jentropies(Tdataset, Ydataset)
                           )
        )
        # Finally, classification with some technique
        
#}
str(cmet_edf)
# show the split entropies
#filter(cmet_edf, type != "XY")
#show all entropies for a data base
print(filter(cmet_edf, dsName == "iris"))
```

```{r visualization in CMET}
# show the split entropies
vetdf <- filter(edf, type != "XY") %>% 
    filter(grepl("PCA|PCAacc",Transform))
fancy <- TRUE
fancy <- FALSE
transfo_cmet <- ggmetern(vetdf, fancy) +
    geom_point(aes(color=Transform, shape=type), size=3) +
    scale_shape_manual(values=c(4, 20, 1)) +
    labs(color="transfo name", shape="Var type")# +
    #geom_label(mapping=aes(as.character(Vars)))#TODO: check with ggtern's website how TODO
transfo_cmet
```

Visualizing the PCA as a source of information:

```{r}
sedf <- 
```

